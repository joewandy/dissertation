\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\AC@reset@newl@bel
\newacro{LC}[LC]{liquid chromatography}
\newacro{MS}[MS]{mass spectrometry}
\newacro{LC/MS}[LC/MS]{liquid chromatography-mass spectrometry}
\newacro{m/z}[m/z]{mass-to-charge ratio}
\newacro{RT}[RT]{retention time}
\newacro{TIC}[TIC]{Total Ion Chromatograms}
\newacro{MW}[MW]{Maximum-Weighted}
\newacro{MWG}[MWG]{Maximum-Weighted-Greedy}
\newacro{MWM}[MWM]{Maximum-Weighted-Mixture}
\citation{Tsai2013a}
\citation{Lee2013}
\AC@undonewlabel{acro:RT}
\newlabel{acro:RT}{{}{}{\listfigurename }{section*.4}{}}
\acronymused{RT}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:intro}{{1}{1}{Introduction}{chapter.1}{}}
\newlabel{sub:thesis-statement}{{1.1}{2}{Thesis Statement}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Thesis Statement}{2}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}List of Contributing Papers}{2}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Overview of Thesis and Research Contributions}{3}{section.1.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Computational Mass Spectrometry Analysis}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:background}{{2}{5}{Computational Mass Spectrometry Analysis}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{5}{section.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The 20 amino acids and the RNA codons that encode them.}}{7}{table.2.1}}
\newlabel{tab:amino-acid}{{2.1}{7}{The 20 amino acids and the RNA codons that encode them}{table.2.1}{}}
\newlabel{my-label}{{2.1}{7}{The 20 amino acids and the RNA codons that encode them}{table.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The layers of -omics and their building blocks.}}{7}{figure.2.1}}
\newlabel{fig:omics-triangle}{{2.1}{7}{The layers of -omics and their building blocks}{figure.2.1}{}}
\citation{mann2003proteomic}
\citation{Panopoulos2012}
\citation{Hirai2004}
\citation{Fiehn2002}
\citation{metzker2010sequencing}
\citation{Alonso2015}
\newlabel{sub:mass-spec}{{2.2}{9}{Measurement Technologies}{section.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Measurement Technologies}{9}{section.2.2}}
\citation{Pan2007}
\citation{Pan2007}
\citation{Smith2014}
\citation{Cao2015}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A typical LC-MS set-up. High performance liquid chromatography instruments are used to separate metabolites (by their chemical properties) in the sample before they are gradually introduced into the mass spectrometer.}}{11}{figure.2.2}}
\newlabel{fig:LC-MS-setup}{{2.2}{11}{A typical LC-MS set-up. High performance liquid chromatography instruments are used to separate metabolites (by their chemical properties) in the sample before they are gradually introduced into the mass spectrometer}{figure.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}LC-MS Analysis in Metabolomics}{11}{section.2.3}}
\citation{Pedrioli2004}
\citation{martens2011mzml}
\citation{Tautenhahn2008}
\citation{Pluskal2010}
\citation{Katajamaa2007}
\citation{Castillo2011}
\citation{Alonso2015}
\citation{Tautenhahn2008}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Raw Data Importing \& Peak Detection}{12}{subsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The resulting raw data (ion chromatograms) produced from an LC-MS experiment. We can view the data as a 2D profile seen from the top \textbf  {(A)} or a 3D profile \textbf  {(B)}. A peak in the data is thus characterised by its intensity value on the m/z and retention time axes. From a scan, a slice of the data on the m/z axis is the mass spectrum \textbf  {(C)}. A collection of mass spectra is produced over the whole range of retention time. Summing over all scans produce the total ion chromatogram (TIC) \textbf  {(D)}, while plotting the intensity values vs. RT for a particular m/z range produces the extracted ion chromatogram (EIC) \textbf  {(E)}.}}{13}{figure.2.3}}
\newlabel{fig:LC-MS-data}{{2.3}{13}{The resulting raw data (ion chromatograms) produced from an LC-MS experiment. We can view the data as a 2D profile seen from the top \textbf {(A)} or a 3D profile \textbf {(B)}. A peak in the data is thus characterised by its intensity value on the m/z and retention time axes. From a scan, a slice of the data on the m/z axis is the mass spectrum \textbf {(C)}. A collection of mass spectra is produced over the whole range of retention time. Summing over all scans produce the total ion chromatogram (TIC) \textbf {(D)}, while plotting the intensity values vs. RT for a particular m/z range produces the extracted ion chromatogram (EIC) \textbf {(E)}}{figure.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces An exemplar pre-processing pipeline of LC-MS metabolomics data.}}{14}{figure.2.4}}
\newlabel{fig:pipeline}{{2.4}{14}{An exemplar pre-processing pipeline of LC-MS metabolomics data}{figure.2.4}{}}
\citation{chokkathukalam2014stable}
\newlabel{sub:alignment-tools}{{2.3.2}{15}{Peak Alignment}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Peak Alignment}{15}{subsection.2.3.2}}
\citation{podwojski2009retention}
\citation{Sakoe1978}
\@writefile{toc}{\contentsline {subsubsection}{Warping-based Alignment Methods}{16}{section*.5}}
\citation{Nielsen1998}
\citation{Christin2008}
\citation{Windig2007}
\citation{VanNederkassel2006}
\citation{podwojski2009retention}
\citation{Listgarten2005}
\citation{Smith2006}
\citation{Lange2007}
\citation{Pluskal2010}
\citation{Fischler1981}
\citation{Lange2008}
\citation{Pluskal2010}
\citation{Hoffmann2012a}
\citation{Ballardini2011}
\citation{Voss2011a}
\citation{Smith2014}
\citation{Duran2003}
\citation{Pluskal2010}
\citation{Ballardini2011}
\citation{Voss2011a}
\citation{Wang2013}
\citation{Hoffmann2012a}
\citation{Lin2013}
\@writefile{toc}{\contentsline {subsubsection}{Direct-matching Alignment Methods}{19}{section*.6}}
\citation{Pluskal2010}
\citation{Voss2011a}
\citation{Smith2006}
\citation{Lee2013}
\citation{Snider2007}
\citation{Keller2008}
\citation{Scheltema2009a}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Gap Filling \& Noise Filtering}{20}{subsection.2.3.3}}
\newlabel{sub:grouping-background}{{2.3.4}{20}{Peak Grouping}{subsection.2.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Peak Grouping}{20}{subsection.2.3.4}}
\citation{Scheltema2009a}
\citation{Scheltema2011}
\citation{Rogers2012}
\citation{Kuhl2012}
\citation{Lee2013}
\citation{Sumner2007}
\newlabel{sub:identification-background}{{2.3.5}{21}{Peak Identification}{subsection.2.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Peak Identification}{21}{subsection.2.3.5}}
\citation{Kind2006}
\citation{Dunn2012}
\citation{Dunn2012}
\citation{DaSilva2015}
\citation{Kuhl2012}
\citation{Creek2011}
\citation{Cao2015}
\citation{Stanstrup2015}
\citation{Rogers2009a}
\citation{Daly2014}
\citation{Hufsky2014}
\citation{kotera2012kegg}
\citation{horai2010massbank}
\citation{pence2010chemspider}
\citation{Xia2010}
\citation{Krumsiek2011a}
\citation{Krumsiek2012}
\citation{Gieger2008}
\citation{DeVos2007a}
\citation{Creek2011}
\citation{mamas2011role}
\citation{Gibney2005}
\citation{Kell2006}
\citation{Gieger2008}
\citation{Kanehisa2010}
\citation{caspi2008metacyc}
\citation{cottret2010metexplore}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Analysis}{24}{subsection.2.3.6}}
\citation{Sandin2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.7}Mass Spectrometry Analysis in Proteomics}{25}{subsection.2.3.7}}
\citation{Chawade2015}
\citation{Podwojski2009}
\citation{Christin2008}
\citation{DeVos2007a}
\citation{Creek2011}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Conclusion}{26}{section.2.4}}
\citation{Hoffmann2007}
\citation{gross2006mass}
\citation{Castillo2011}
\citation{Smith2014}
\citation{Gika2014}
\citation{Alonso2015}
\citation{Sandin2014}
\citation{Megger2013}
\citation{Smith2014}
\citation{xu2005survey}
\citation{Jain2010}
\citation{DeSouza2006}
\citation{Frank2007}
\citation{Rogers2012}
\citation{Rogers2012}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Probabilistic Modelling}{28}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:ml-background}{{3}{28}{Probabilistic Modelling}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{28}{section.3.1}}
\citation{Daly2014}
\citation{Rogers2009a}
\citation{Silva2014}
\citation{Allen2014}
\citation{Allen2016}
\citation{Creek2011}
\citation{Cao2015}
\citation{Stanstrup2015}
\citation{Heinonen2012a}
\citation{Duhrkop2015}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Mixture Model Clustering}{29}{section.3.2}}
\newlabel{sub:background-mixture-model-clustering}{{3.2}{29}{Mixture Model Clustering}{section.3.2}{}}
\citation{Rasmussen2000}
\newlabel{eq:background-bayesian}{{3.1}{30}{Mixture Model Clustering}{equation.3.2.1}{}}
\newlabel{eq:background-posterior-predictive}{{3.2}{30}{Mixture Model Clustering}{equation.3.2.2}{}}
\newlabel{eq:background-finite-mixture}{{3.3}{30}{Mixture Model Clustering}{equation.3.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Graphical models of (1) a finite mixture model, which is extended into (2) an infinite mixture model, to cluster peaks by their retention time (RT) values. Circles denotes random variables, squares denote fixed parameters, while the shaded node denotes an observed peak's RT.}}{31}{figure.3.1}}
\newlabel{fig:background-mixture-plate-diagram}{{3.1}{31}{Graphical models of (1) a finite mixture model, which is extended into (2) an infinite mixture model, to cluster peaks by their retention time (RT) values. Circles denotes random variables, squares denote fixed parameters, while the shaded node denotes an observed peak's RT}{figure.3.1}{}}
\newlabel{eq:background-prior-gaussian}{{3.6}{32}{Mixture Model Clustering}{equation.3.2.6}{}}
\newlabel{eq:background-zn_pmf}{{3.7}{32}{Mixture Model Clustering}{equation.3.2.7}{}}
\newlabel{eq:background-z-given-pi}{{3.8}{32}{Mixture Model Clustering}{equation.3.2.8}{}}
\newlabel{eq:background-mixture-likelihood}{{3.9}{32}{Mixture Model Clustering}{equation.3.2.9}{}}
\citation{gelman2014bayesian}
\newlabel{eq:background-pi-given-alpha}{{3.10}{33}{Mixture Model Clustering}{equation.3.2.10}{}}
\newlabel{eq:example-full-joint-dist}{{3.11}{33}{Mixture Model Clustering}{equation.3.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Gibbs Sampling for a Finite Mixture Model}{33}{subsection.3.2.1}}
\newlabel{eq:background-mixture-posterior}{{3.12}{33}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.12}{}}
\newlabel{eq:background-mixture-expanded-posterior}{{3.13}{33}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.13}{}}
\newlabel{eq:background-mixture-conditional-z}{{3.14}{34}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.14}{}}
\newlabel{eq:background-posterior_mu_k}{{3.15}{34}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.15}{}}
\newlabel{eq:background-solving-posterior-mu_k}{{3.16}{34}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.16}{}}
\newlabel{eq:background-tilde-mu-sigma}{{3.17}{34}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.17}{}}
\citation{gelman2014bayesian}
\newlabel{eq:background-mixture-conditional-pi}{{3.18}{35}{Gibbs Sampling for a Finite Mixture Model}{equation.3.2.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Collapsed Gibbs Sampling for a Finite Mixture Model}{35}{subsection.3.2.2}}
\citation{murphy2012machine}
\newlabel{eq:background-collapsed-gibbs}{{3.19}{36}{Collapsed Gibbs Sampling for a Finite Mixture Model}{equation.3.2.19}{}}
\newlabel{eq:background-tilde-mu-sigma-variance}{{3.20}{36}{Collapsed Gibbs Sampling for a Finite Mixture Model}{equation.3.2.20}{}}
\newlabel{eq:background-tilde-mu-sigma-precision}{{3.21}{36}{Collapsed Gibbs Sampling for a Finite Mixture Model}{equation.3.2.21}{}}
\newlabel{eq:background-integrated-pi}{{3.22}{36}{Collapsed Gibbs Sampling for a Finite Mixture Model}{equation.3.2.22}{}}
\citation{hjort2010bayesian}
\citation{ferguson1973bayesian}
\citation{murphy2012machine}
\citation{Rasmussen2000}
\citation{hjort2010bayesian}
\citation{teh2011dirichlet}
\citation{ishwaran2011gibbs}
\newlabel{background-dp-clustering}{{3.3}{37}{Dirichlet Process Mixture Model Clustering}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Dirichlet Process Mixture Model Clustering}{37}{section.3.3}}
\citation{ishwaran2011gibbs}
\newlabel{eq:background-stick-breaking-construction}{{3.23}{38}{Dirichlet Process Mixture Model Clustering}{equation.3.3.23}{}}
\newlabel{eq:background-pi-gem}{{3.24}{38}{Dirichlet Process Mixture Model Clustering}{equation.3.3.24}{}}
\citation{teh2011dirichlet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Two samples of $G$, plotted up to 1000 discrete values, generated by a Dirichlet Process with $\alpha =1$ (left) and $\alpha =1000$ (right) and a base distribution $\mathcal  {N}(0, 1)$. We see that $\alpha $ affects how smooth the resulting discretisation of $H$ is in $G$.}}{39}{figure.3.2}}
\newlabel{fig:g-from-dp-stick}{{3.2}{39}{Two samples of $G$, plotted up to 1000 discrete values, generated by a Dirichlet Process with $\alpha =1$ (left) and $\alpha =1000$ (right) and a base distribution $\mathcal {N}(0, 1)$. We see that $\alpha $ affects how smooth the resulting discretisation of $H$ is in $G$}{figure.3.2}{}}
\newlabel{eq:background-infinite-mixture-dp}{{3.26}{39}{Dirichlet Process Mixture Model Clustering}{equation.3.3.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces An illustration of the generative process for the DP mixture model in eq. (\ref  {eq:background-infinite-mixture-dp}). First, we require a base distribution to sample for discrete values, shown in \textbf  {(A)}. Given $H$ and some concentration parameter $\alpha $, we generate a discrete distribution $G$. In \textbf  {(B)}, we see that $G$ contains two unique discrete values sampled from $H$, represented by the red and green crosses. Each discrete value in G $\phi _k$ is also a cluster mean $\mu _k$. \textbf  {(C)} The noisy observed values is generated by sampling for $\mu _k$ from $G$, and sampling for $y_n$ conditioned on the $\mu _k$.}}{40}{figure.3.3}}
\newlabel{fig:g-from-dp}{{3.3}{40}{An illustration of the generative process for the DP mixture model in eq. (\ref {eq:background-infinite-mixture-dp}). First, we require a base distribution to sample for discrete values, shown in \textbf {(A)}. Given $H$ and some concentration parameter $\alpha $, we generate a discrete distribution $G$. In \textbf {(B)}, we see that $G$ contains two unique discrete values sampled from $H$, represented by the red and green crosses. Each discrete value in G $\phi _k$ is also a cluster mean $\mu _k$. \textbf {(C)} The noisy observed values is generated by sampling for $\mu _k$ from $G$, and sampling for $y_n$ conditioned on the $\mu _k$}{figure.3.3}{}}
\citation{frigyik2010introduction}
\citation{aldous1985exchangeability}
\newlabel{background-cgs-dpmixture}{{3.3.1}{41}{Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model }{41}{subsection.3.3.1}}
\newlabel{eq:background-integrated-pi-symmetric}{{3.27}{41}{Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model}{equation.3.3.27}{}}
\newlabel{eq:background-crp}{{3.28}{41}{Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model}{equation.3.3.28}{}}
\newlabel{eq:background-infinite-mixture-model-sampling}{{3.29}{41}{Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model}{equation.3.3.29}{}}
\citation{Rasmussen2000}
\citation{teh2005hierarchical}
\citation{teh2012hierarchical}
\newlabel{eq:background-new-table-likelihood}{{3.30}{42}{Collapsed Gibbs Sampling for a Dirichlet Process Mixture Model}{equation.3.3.30}{}}
\newlabel{background-hdp-clustering}{{3.4}{42}{Hierarchical Dirichlet Process Mixture Model Clustering}{section.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Hierarchical Dirichlet Process Mixture Model Clustering}{42}{section.3.4}}
\newlabel{eq:background-hdp-process}{{3.31}{43}{Hierarchical Dirichlet Process Mixture Model Clustering}{equation.3.4.31}{}}
\citation{teh2005hierarchical}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces An illustration of the generative process for the HDP mixture model defined in eq. (\ref  {eq:background-infinite-mixture-hdp}). Similar to the DP mixture, we have a base distribution shown in \textbf  {(A)}. Given $H$ and some concentration parameter $\alpha $, we generate a global distribution $G_0$. In \textbf  {(B)}, we see that $G_0$ contains three unique discrete values. We then generate a file-specific distribution $G_j$ by sampling from a DP with $G_0$ as the base distribution. As a consequence, $G_j$ contains only discrete values copied from $G_0$. In \textbf  {(C)}, the noisy observed values within each file is generated by sampling for $\mu _k$ from $G_j$, and sampling for $y_n$ conditioned on the $\mu _k$.}}{44}{figure.3.4}}
\newlabel{fig:g-from-hdp}{{3.4}{44}{An illustration of the generative process for the HDP mixture model defined in eq. (\ref {eq:background-infinite-mixture-hdp}). Similar to the DP mixture, we have a base distribution shown in \textbf {(A)}. Given $H$ and some concentration parameter $\alpha $, we generate a global distribution $G_0$. In \textbf {(B)}, we see that $G_0$ contains three unique discrete values. We then generate a file-specific distribution $G_j$ by sampling from a DP with $G_0$ as the base distribution. As a consequence, $G_j$ contains only discrete values copied from $G_0$. In \textbf {(C)}, the noisy observed values within each file is generated by sampling for $\mu _k$ from $G_j$, and sampling for $y_n$ conditioned on the $\mu _k$}{figure.3.4}{}}
\newlabel{eq:background-infinite-mixture-hdp}{{3.32}{44}{Hierarchical Dirichlet Process Mixture Model Clustering}{equation.3.4.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Gibbs Sampling for a Hierarchical Dirichlet Process Mixture Model}{45}{subsection.3.4.1}}
\newlabel{eq:background-hdp-conditional}{{3.33}{45}{Gibbs Sampling for a Hierarchical Dirichlet Process Mixture Model}{Item.16}{}}
\citation{teh2005hierarchical}
\newlabel{eq:background-hdp-conditional-top-level}{{3.34}{47}{Gibbs Sampling for a Hierarchical Dirichlet Process Mixture Model}{Item.17}{}}
\newlabel{eq:background-tilde-hdp-posterior}{{3.36}{47}{Gibbs Sampling for a Hierarchical Dirichlet Process Mixture Model}{equation.3.4.36}{}}
\citation{kim2006hierarchical}
\citation{kim2006hierarchical}
\citation{Blei2003}
\citation{rogers2005latent}
\citation{weinshall2013lda}
\citation{das2015gaussian}
\newlabel{background-lda}{{3.5}{48}{Latent Dirichet Allocation}{section.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Latent Dirichet Allocation}{48}{section.3.5}}
\newlabel{eq:background-lda-model}{{3.37}{49}{Latent Dirichet Allocation}{equation.3.5.37}{}}
\newlabel{eq:background-lda-full-joint}{{3.38}{49}{Latent Dirichet Allocation}{equation.3.5.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{49}{subsection.3.5.1}}
\citation{carpenter2010integrating}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Graphical model of the Latent Dirichlet Allocation model. Circles denotes random variables, while the shaded node denotes the observed word value.}}{50}{figure.3.5}}
\newlabel{fig:background-lda}{{3.5}{50}{Graphical model of the Latent Dirichlet Allocation model. Circles denotes random variables, while the shaded node denotes the observed word value}{figure.3.5}{}}
\newlabel{eq:lda-gibbs}{{3.39}{50}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.39}{}}
\citation{carpenter2010integrating}
\newlabel{eq:lda-gibbs-prior}{{3.40}{51}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.40}{}}
\newlabel{eq:lda-gibbs-prior-simple}{{3.41}{51}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.41}{}}
\newlabel{eq:lda-gibbs-likelihood}{{3.42}{51}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.42}{}}
\newlabel{eq:lda-gibbs-likelihood-simple}{{3.43}{51}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.43}{}}
\newlabel{eq:lda-gibbs-combined}{{3.44}{51}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.44}{}}
\newlabel{eq:background-lda-updated-theta-phi}{{3.45}{52}{Collapsed Gibbs Sampling for Latent Dirichlet Allocation}{equation.3.5.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Conclusion}{52}{section.3.6}}
\citation{Podwojski2009}
\citation{Christin2008}
\citation{Smith2013}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Incorporating Clustering Information into Peak Alignment}{54}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:matching}{{4}{54}{Incorporating Clustering Information into Peak Alignment}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{54}{section.4.1}}
\citation{wandy2015incorporating}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  Illustrative example of the incorporation of grouping information into the similarity score. Each node in the figure is a peak feature, and dotted ovals represent groups of IP peaks, e.g. isotopes, fragments, etc. Initially weights (e.g. $W_{AE}$) are computed for pairs of peaks (one from each run) with m/z and RT within pre-defined thresholds. These weights are converted into an overall score by incorporating grouping information. For example, peak pairs $(A,E)$ and $(B,G)$ are both within the threshold. Because $A$ and $B$ are in the same group, and $E$ and $G$ are in the same group, the weights between pairs $(A,E)$ and $(B,G)$ are upweighted. Peak $J$ is not related to any peaks that could be matched with $A$'s IP peaks and the similarity between $A$ and $J$ is therefore downweighted (because $\alpha \leq 1$). The same applies to similarities between pairs $(C,H)$ and $(D,I)$.}}{55}{figure.4.1}}
\newlabel{fig:computingweight}{{4.1}{55}{Illustrative example of the incorporation of grouping information into the similarity score. Each node in the figure is a peak feature, and dotted ovals represent groups of IP peaks, e.g. isotopes, fragments, etc. Initially weights (e.g. $W_{AE}$) are computed for pairs of peaks (one from each run) with m/z and RT within pre-defined thresholds. These weights are converted into an overall score by incorporating grouping information. For example, peak pairs $(A,E)$ and $(B,G)$ are both within the threshold. Because $A$ and $B$ are in the same group, and $E$ and $G$ are in the same group, the weights between pairs $(A,E)$ and $(B,G)$ are upweighted. Peak $J$ is not related to any peaks that could be matched with $A$'s IP peaks and the similarity between $A$ and $J$ is therefore downweighted (because $\alpha \leq 1$). The same applies to similarities between pairs $(C,H)$ and $(D,I)$}{figure.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Related Work}{55}{section.4.2}}
\citation{Voss2011a}
\citation{Gusfield1989}
\citation{Wang2013}
\citation{Kuhn1955}
\citation{Maximum2011}
\newlabel{sub:direct-matching}{{4.3}{56}{A Direct Matching Method That Incorporates Clustering Information}{section.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}A Direct Matching Method That Incorporates Clustering Information}{56}{section.4.3}}
\citation{Voss2011a}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Feature Similarity}{57}{subsection.4.3.1}}
\newlabel{sub:incorporating-grouping}{{4.3.2}{57}{Combining Related Peak Information}{subsection.4.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Combining Related Peak Information}{57}{subsection.4.3.2}}
\newlabel{eq:combining-eq}{{4.2}{57}{Combining Related Peak Information}{equation.4.3.2}{}}
\newlabel{eq:L-multiply}{{4.3}{58}{Combining Related Peak Information}{equation.4.3.3}{}}
\AC@undonewlabel{acro:MW}
\newlabel{acro:MW}{{4.3.2}{58}{Combining Related Peak Information}{section*.8}{}}
\acronymused{MW}
\newlabel{sub:rt-clustering-greedy}{{4.3.3}{58}{Greedy Clustering of IP peaks}{subsection.4.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Greedy Clustering of IP peaks}{58}{subsection.4.3.3}}
\newlabel{sub:rt-clustering-mixture}{{4.3.4}{59}{Mixture Model Clustering of IP peaks}{subsection.4.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Mixture Model Clustering of IP peaks}{59}{subsection.4.3.4}}
\citation{Castillo2011}
\citation{Smith2013a}
\citation{Lange2008}
\citation{Smith2013}
\newlabel{eq:table_likelihood}{{4.10}{60}{Mixture Model Clustering of IP peaks}{equation.4.3.10}{}}
\newlabel{eq:15}{{4.11}{60}{Mixture Model Clustering of IP peaks}{equation.4.3.11}{}}
\newlabel{eq:15-1}{{4.12}{60}{Mixture Model Clustering of IP peaks}{equation.4.3.12}{}}
\newlabel{sub:evaluation-study}{{4.4}{60}{Evaluation Study}{section.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Evaluation Study}{60}{section.4.4}}
\citation{Lange2008}
\citation{Tsai2013a}
\citation{Lange2008}
\citation{Pluskal2010}
\citation{Ballardini2011}
\citation{Voss2011a}
\citation{Tsai2013a}
\citation{Creek2011}
\citation{Lange2008}
\citation{Lange2008}
\citation{Lange2008}
\citation{Creek2011}
\citation{Scheltema2011}
\newlabel{sub:proteomic-dataset}{{4.4.1}{61}{Proteomic Datasets}{subsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Proteomic Datasets}{61}{subsection.4.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces No. of features in the proteomic (P1 and P2) datasets. Note that fraction 060 is not present in P2.}}{62}{table.4.1}}
\newlabel{tab:No.-of-features-P1}{{4.1}{62}{No. of features in the proteomic (P1 and P2) datasets. Note that fraction 060 is not present in P2}{table.4.1}{}}
\newlabel{sub:metabolomic-dataset}{{4.4.2}{62}{Metabolomic Datasets}{subsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Metabolomic Datasets}{62}{subsection.4.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces No. of features in the full metabolomic dataset}}{62}{table.4.2}}
\newlabel{tab:No.-of-features-metabolomic}{{4.2}{62}{No. of features in the full metabolomic dataset}{table.4.2}{}}
\citation{Tsai2013a}
\citation{Tsai2013a}
\citation{Tsai2013a}
\citation{Tsai2013a}
\citation{Smith2013}
\citation{Smith2013}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces List of common adduct types in positive ionisation mode for ESI.}}{63}{table.4.3}}
\newlabel{tab:adducts}{{4.3}{63}{List of common adduct types in positive ionisation mode for ESI}{table.4.3}{}}
\newlabel{sub:glycomic-dataset}{{4.4.3}{63}{Glycomic Dataset}{subsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Glycomic Dataset}{63}{subsection.4.4.3}}
\newlabel{sub:experimental-setup}{{4.4.4}{63}{Experimental setup}{subsection.4.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Experimental setup}{63}{subsection.4.4.4}}
\AC@undonewlabel{acro:m/z}
\newlabel{acro:m/z}{{4.4.4}{63}{Experimental setup}{section*.9}{}}
\acronymused{m/z}
\acronymused{RT}
\acronymused{m/z}
\acronymused{RT}
\citation{Lange2008}
\citation{Ballardini2011}
\citation{Voss2011a}
\citation{Smith2013}
\citation{Lange2008}
\citation{Voss2011a}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces No. of features in the full glycomic dataset from \cite  {Tsai2013a}}}{64}{table.4.4}}
\newlabel{tab:No.-of-features-glycomic}{{4.4}{64}{No. of features in the full glycomic dataset from \cite {Tsai2013a}}{table.4.4}{}}
\acronymused{m/z}
\acronymused{RT}
\acronymused{m/z}
\acronymused{RT}
\citation{Wang2013}
\citation{Pluskal2010}
\citation{Voss2011a}
\newlabel{sec:comp}{{4.4.5}{65}{Other Alignment Tools For Comparison}{subsection.4.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Other Alignment Tools For Comparison}{65}{subsection.4.4.5}}
\citation{Lange2008}
\citation{Lange2008}
\citation{Tsai2013a}
\citation{Tsai2013a}
\newlabel{sub:parameters-optimisation}{{4.4.6}{66}{Parameter Optimisation}{subsection.4.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Parameter Optimisation}{66}{subsection.4.4.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Results and Discussions}{67}{section.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Proteomics Experiments}{67}{subsection.4.5.1}}
\newlabel{sub:Proteomics-experiments}{{4.5.1}{67}{Proteomics Experiments}{subsection.4.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Single-fraction Experiment}{67}{section*.10}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces F$_1$ scores for the single-fraction experiment results on the P1 dataset. The tool with the highest F$_1$ score for each fraction is highlighted in bold. The results for `All' show the average F$_1$ scores of individual fractions.}}{68}{table.4.5}}
\newlabel{tab:Detailed-Result--P1}{{4.5}{68}{F$_1$ scores for the single-fraction experiment results on the P1 dataset. The tool with the highest F$_1$ score for each fraction is highlighted in bold. The results for `All' show the average F$_1$ scores of individual fractions}{table.4.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces F$_1$ scores for the single-fraction experiment results on the P2 dataset. The tool with the highest F$_1$ score for each fraction is highlighted in bold. The results for `All' show the average F$_1$ scores of individual fractions.}}{68}{table.4.6}}
\newlabel{tab:Detailed-Result--P2}{{4.6}{68}{F$_1$ scores for the single-fraction experiment results on the P2 dataset. The tool with the highest F$_1$ score for each fraction is highlighted in bold. The results for `All' show the average F$_1$ scores of individual fractions}{table.4.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Multiple-fractions Experiment}{68}{section*.11}}
\newlabel{fig:figA}{{4.2a}{69}{Subfigure 4 4.2a}{subfigure.4.2.1}{}}
\newlabel{sub@fig:figA}{{(a)}{a}{Subfigure 4 4.2a\relax }{subfigure.4.2.1}{}}
\newlabel{fig:figB}{{4.2b}{69}{Subfigure 4 4.2b}{subfigure.4.2.2}{}}
\newlabel{sub@fig:figB}{{(b)}{b}{Subfigure 4 4.2b\relax }{subfigure.4.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P1 dataset.}}{69}{figure.4.2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {P1 Fraction 000}}}{69}{subfigure.2.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {P1 Fraction 100}}}{69}{subfigure.2.2}}
\newlabel{fig:single-fraction-results-P1}{{4.2}{69}{Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P1 dataset}{figure.4.2}{}}
\newlabel{fig:figC}{{4.3a}{69}{Subfigure 4 4.3a}{subfigure.4.3.1}{}}
\newlabel{sub@fig:figC}{{(a)}{a}{Subfigure 4 4.3a\relax }{subfigure.4.3.1}{}}
\newlabel{fig:figD}{{4.3b}{69}{Subfigure 4 4.3b}{subfigure.4.3.2}{}}
\newlabel{sub@fig:figD}{{(b)}{b}{Subfigure 4 4.3b\relax }{subfigure.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P2 dataset.}}{69}{figure.4.3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {P2 Fraction 000}}}{69}{subfigure.3.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {P2 Fraction 100}}}{69}{subfigure.3.2}}
\newlabel{fig:single-fraction-results-P2}{{4.3}{69}{Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P2 dataset}{figure.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Multiple-fractions experiment results for the P1 dataset. For each training fraction, the reported testing performance is the average of individual F$_1$ scores from the testing fractions. The top-performing method (highest F$_1$ score) is highlighted in bold.}}{70}{table.4.7}}
\newlabel{tab:within-P1}{{4.7}{70}{Multiple-fractions experiment results for the P1 dataset. For each training fraction, the reported testing performance is the average of individual F$_1$ scores from the testing fractions. The top-performing method (highest F$_1$ score) is highlighted in bold}{table.4.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Multiple-fractions experiment results for the P2 dataset. For each training fraction, the reported testing performance is the average of individual F$_1$ scores from the testing fractions. The top-performing method (highest F$_1$ score) is highlighted in bold.}}{70}{table.4.8}}
\newlabel{tab:within-P2}{{4.8}{70}{Multiple-fractions experiment results for the P2 dataset. For each training fraction, the reported testing performance is the average of individual F$_1$ scores from the testing fractions. The top-performing method (highest F$_1$ score) is highlighted in bold}{table.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Metabolomic and Glycomic Datasets}{71}{subsection.4.5.2}}
\newlabel{sub:Metabolomic-glycomic-experiments}{{4.5.2}{71}{Metabolomic and Glycomic Datasets}{subsection.4.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Training performance shows the best F$_1$ scores obtained by each method on 30 pairs of randomly-selected metabolomic and glycomic training sets.}}{72}{figure.4.4}}
\newlabel{fig:glyco-datasets-alignment-train}{{4.4}{72}{Training performance shows the best F$_1$ scores obtained by each method on 30 pairs of randomly-selected metabolomic and glycomic training sets}{figure.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Testing performance shows how well each method generalise on the 30 different testing sets, each evaluated using the optimal training parameters from its corresponding training set.}}{72}{figure.4.5}}
\newlabel{fig:glyco-datasets-alignment-test}{{4.5}{72}{Testing performance shows how well each method generalise on the 30 different testing sets, each evaluated using the optimal training parameters from its corresponding training set}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparisons in matching performance when greedy clustering with retention time (MWG(RT)) and peak shape correlations (MWG(RT+PS)) are used.}}{73}{figure.4.6}}
\newlabel{fig:MWG-RT-andPS}{{4.6}{73}{Comparisons in matching performance when greedy clustering with retention time (MWG(RT)) and peak shape correlations (MWG(RT+PS)) are used}{figure.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Running Time}{73}{subsection.4.5.3}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Example measured execution time in seconds on fractions of the P1 dataset}}{74}{table.4.9}}
\newlabel{tab:Running-Time-P1}{{4.9}{74}{Example measured execution time in seconds on fractions of the P1 dataset}{table.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Conclusion}{74}{section.4.6}}
\newlabel{sec:conc}{{4.6}{74}{Conclusion}{section.4.6}{}}
\acronymused{RT}
\acronymused{RT}
\acronymused{RT}
\citation{Rogers2012}
\citation{Daly2014}
\citation{Maximum2011}
\citation{Smith2014}
\acronymused{RT}
\AC@undonewlabel{acro:LC}
\newlabel{acro:LC}{{4.6}{75}{Conclusion}{section*.12}{}}
\acronymused{LC}
\acronymused{RT}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Precursor Clustering of Ionisation Product Peaks}{76}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:precursor-clustering}{{5}{76}{Precursor Clustering of Ionisation Product Peaks}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{76}{section.5.1}}
\citation{Smith2013}
\citation{Smith2015}
\citation{Daly2014}
\citation{Kuhl2012}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Related Work}{77}{section.5.2}}
\citation{Melamud2010}
\citation{Brodsky2010}
\citation{Landan2009}
\citation{Thompson1994}
\citation{Notredame2000}
\citation{Penn2010}
\citation{Redelings2005}
\citation{Bradley2009}
\citation{Jeong2012}
\citation{Jeong2012}
\citation{GhanatBari2014b}
\citation{GhanatBari2014b}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Methods}{79}{section.5.3}}
\newlabel{sub:ip-clustering}{{5.3.1}{80}{PrecursorCluster: clustering of ionization product peaks}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}PrecursorCluster: clustering of ionization product peaks}{80}{subsection.5.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces  The proposed workflow. The input to PrecursorCluster is a list of m/z, RT and intensity values. During the enumeration stage, candidate IP clusters are generated from each peak through the M+H transformation. In this example, Peak 1 and Peak 4 generate candidate IP clusters with precursor masses $q_a$ (blue) and $q_b$ (red). In the inference stage, Peak 1 and Peak 2 are clustered to $q_a$ through transformation M+H and M+Na with probabilities 1.0. Peak 3 has a valid transformation to $q_a$, but is not allowed to join that cluster since its intensity is $>$ than the intensity of the $[M+H]^+$ peak that generated the cluster (peak 1). Peak 4 can join the $q_a$ cluster through the 2M+H transformation (with probability 0.62) or form its own candidate M+H cluster having the precursor mass $q_b$ (with probability 0.38.) The latter allows for Peak 5 to join that cluster through the M+NH4 transformation (with probability 0.43). The final clustering is established by taking the \textit  {maximum a posteriori} assignment for each peak feature. Non-empty IP clusters can be aligned by matching their posterior precursor mass and RT values (Fig.\nobreakspace  {}\ref  {fig:01}B) or through a second-stage clustering process (Fig.\nobreakspace  {}\ref  {fig:01}C). The correspondence of peak features in matched IP clusters is constructed by grouping peak features having the same transformation types, shown as the gray dotted lines in Figures\nobreakspace  {}\ref  {fig:01}B \& C.}}{81}{figure.5.1}}
\newlabel{fig:01}{{5.1}{81}{The proposed workflow. The input to PrecursorCluster is a list of m/z, RT and intensity values. During the enumeration stage, candidate IP clusters are generated from each peak through the M+H transformation. In this example, Peak 1 and Peak 4 generate candidate IP clusters with precursor masses $q_a$ (blue) and $q_b$ (red). In the inference stage, Peak 1 and Peak 2 are clustered to $q_a$ through transformation M+H and M+Na with probabilities 1.0. Peak 3 has a valid transformation to $q_a$, but is not allowed to join that cluster since its intensity is $>$ than the intensity of the $[M+H]^+$ peak that generated the cluster (peak 1). Peak 4 can join the $q_a$ cluster through the 2M+H transformation (with probability 0.62) or form its own candidate M+H cluster having the precursor mass $q_b$ (with probability 0.38.) The latter allows for Peak 5 to join that cluster through the M+NH4 transformation (with probability 0.43). The final clustering is established by taking the \textit {maximum a posteriori} assignment for each peak feature. Non-empty IP clusters can be aligned by matching their posterior precursor mass and RT values (Fig.~\ref {fig:01}B) or through a second-stage clustering process (Fig.~\ref {fig:01}C). The correspondence of peak features in matched IP clusters is constructed by grouping peak features having the same transformation types, shown as the gray dotted lines in Figures~\ref {fig:01}B \& C}{figure.5.1}{}}
\newlabel{eq:likelihood}{{5.1}{82}{PrecursorCluster: clustering of ionization product peaks}{equation.5.3.1}{}}
\newlabel{eq:mass-term-pc}{{5.2}{82}{PrecursorCluster: clustering of ionization product peaks}{equation.5.3.2}{}}
\newlabel{eq:mass-prior-pc}{{5.3}{82}{PrecursorCluster: clustering of ionization product peaks}{equation.5.3.3}{}}
\newlabel{eq:rt-term-pc}{{5.4}{82}{PrecursorCluster: clustering of ionization product peaks}{equation.5.3.4}{}}
\newlabel{eq:rt-prior-pc}{{5.5}{82}{PrecursorCluster: clustering of ionization product peaks}{equation.5.3.5}{}}
\newlabel{sub:ip-clustering-gibbs}{{5.3.1}{83}{Gibbs Sampling for PrecursorCluster}{section*.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gibbs Sampling for PrecursorCluster}{83}{section*.14}}
\newlabel{eq:finite_conditional}{{5.6}{83}{Gibbs Sampling for PrecursorCluster}{equation.5.3.6}{}}
\newlabel{eq:mass-term}{{5.7}{83}{Gibbs Sampling for PrecursorCluster}{equation.5.3.7}{}}
\newlabel{eq:rt-term}{{5.8}{83}{Gibbs Sampling for PrecursorCluster}{equation.5.3.8}{}}
\newlabel{sub:cluster-match}{{5.3.2}{83}{Cluster-Match: direct matching of ionization product clusters}{subsection.5.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Cluster-Match: direct matching of ionization product clusters}{83}{subsection.5.3.2}}
\citation{Maximum2011}
\citation{Voss2011a}
\citation{Pluskal2010}
\citation{Smith2013}
\newlabel{sub:cluster-cluster}{{5.3.3}{84}{Cluster-Cluster: across-run clustering of ionization product clusters}{subsection.5.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Cluster-Cluster: across-run clustering of ionization product clusters}{84}{subsection.5.3.3}}
\newlabel{eq:second-stage-likelihood}{{5.12}{86}{Cluster-Cluster: across-run clustering of ionization product clusters}{equation.5.3.12}{}}
\newlabel{eq:second-mass-term}{{5.13}{86}{Cluster-Cluster: across-run clustering of ionization product clusters}{equation.5.3.13}{}}
\newlabel{eq:second-mass-prior}{{5.14}{86}{Cluster-Cluster: across-run clustering of ionization product clusters}{equation.5.3.14}{}}
\newlabel{eq:second-rt-term}{{5.15}{86}{Cluster-Cluster: across-run clustering of ionization product clusters}{equation.5.3.15}{}}
\newlabel{eq:second-rt-prior}{{5.16}{86}{Cluster-Cluster: across-run clustering of ionization product clusters}{equation.5.3.16}{}}
\newlabel{sub:cluster-cluster-gibbs}{{5.3.3}{87}{Gibbs Sampling for Cluster-Cluster}{section*.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{Gibbs Sampling for Cluster-Cluster}{87}{section*.15}}
\newlabel{eq:table_likelihood-cc}{{5.17}{87}{Gibbs Sampling for Cluster-Cluster}{equation.5.3.17}{}}
\newlabel{eq:15-2}{{5.18}{87}{Gibbs Sampling for Cluster-Cluster}{equation.5.3.18}{}}
\citation{Scheltema2011}
\citation{Lange2008}
\citation{Pluskal2010}
\citation{Ballardini2011}
\citation{Voss2011a}
\citation{Sandin2013}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Evaluation Study}{88}{section.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Evaluation Datasets}{88}{subsection.5.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces List of common adduct transformations in positive mode used for the precursor clustering of the Standard and Beer runs.}}{88}{table.5.1}}
\newlabel{Tab:transformation}{{5.1}{88}{List of common adduct transformations in positive mode used for the precursor clustering of the Standard and Beer runs}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Performance Measures}{88}{subsection.5.4.2}}
\newlabel{sub:Performance-Measures}{{5.4.2}{88}{Performance Measures}{subsection.5.4.2}{}}
\newlabel{sub:evaluation_procedure}{{5.4.3}{89}{Evaluation Procedure}{subsection.5.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Evaluation Procedure}{89}{subsection.5.4.3}}
\newlabel{sub:parameters}{{5.4.4}{90}{Parameter Optimization}{subsection.5.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Parameter Optimization}{90}{subsection.5.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Results and Discussions}{91}{section.5.5}}
\newlabel{sub:precursor-cluster-results}{{5.5.1}{92}{Ionization Product Clustering from PrecursorCluster}{subsection.5.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Ionization Product Clustering from PrecursorCluster}{92}{subsection.5.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces  Different IP clusters in four different Standard runs, identified as Cysteic acid (Figure\nobreakspace  {}\ref  {fig:06}A) and melatonin (Figure\nobreakspace  {}\ref  {fig:06}B). The MAP transformation type of a peak and its probability are annotated as a labelled arrow and the bracketed number beside. According to the ground truth, all member peaks with the same transformation type should be aligned.}}{92}{figure.5.2}}
\newlabel{fig:06}{{5.2}{92}{Different IP clusters in four different Standard runs, identified as Cysteic acid (Figure~\ref {fig:06}A) and melatonin (Figure~\ref {fig:06}B). The MAP transformation type of a peak and its probability are annotated as a labelled arrow and the bracketed number beside. According to the ground truth, all member peaks with the same transformation type should be aligned}{figure.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces The number of peak features and the counts of singleton and non-singleton IP clusters in each run of the Standard and Beer datasets. A singleton cluster is defined to be an IP cluster having only one member peak after MAP assignments, while a non-singleton IP cluster has more than one member peaks. The last column in the Table shows the counts of non-singleton IP clusters and also the percentage of non-singleton IP clusters from the total IP clusters in that run. }}{93}{table.5.2}}
\newlabel{Tab:cluster-counts}{{5.2}{93}{The number of peak features and the counts of singleton and non-singleton IP clusters in each run of the Standard and Beer datasets. A singleton cluster is defined to be an IP cluster having only one member peak after MAP assignments, while a non-singleton IP cluster has more than one member peaks. The last column in the Table shows the counts of non-singleton IP clusters and also the percentage of non-singleton IP clusters from the total IP clusters in that run}{table.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces  Ionization product cluster sizes for all runs in the Standard and Beer datasets. For any given size, the number of clusters are generally more consistent in the Beer runs compared to the Standard runs, which shows greater variability due to the differences in the number of peak features per run.}}{94}{figure.5.3}}
\newlabel{fig:cluster-counts}{{5.3}{94}{Ionization product cluster sizes for all runs in the Standard and Beer datasets. For any given size, the number of clusters are generally more consistent in the Beer runs compared to the Standard runs, which shows greater variability due to the differences in the number of peak features per run}{figure.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Barcharts showing the counts of transformation types in all Standard and Beer runs, excluding the M+H transformation.}}{94}{figure.5.4}}
\newlabel{fig:counts-trans}{{5.4}{94}{Barcharts showing the counts of transformation types in all Standard and Beer runs, excluding the M+H transformation}{figure.5.4}{}}
\newlabel{sub:cluster-match-results}{{5.5.2}{95}{Improved Alignment Performance from Cluster-Match}{subsection.5.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Improved Alignment Performance from Cluster-Match}{95}{subsection.5.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces  All the training results obtained by varying the m/z and RT window parameters from the alignment of the entire 30 sets of pairwise Standard runs (top row) and the 3 Beer runs (bottom row). For MWG, the grouping parameter $t$ and score contribution $\alpha $ were also varied, while for Cluster-Match, the same set parameters of first-stage clustering was used for all input files.}}{96}{figure.5.5}}
\newlabel{fig:training-results}{{5.5}{96}{All the training results obtained by varying the m/z and RT window parameters from the alignment of the entire 30 sets of pairwise Standard runs (top row) and the 3 Beer runs (bottom row). For MWG, the grouping parameter $t$ and score contribution $\alpha $ were also varied, while for Cluster-Match, the same set parameters of first-stage clustering was used for all input files}{figure.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces  The best training and testing $F_1$-scores obtained from the alignment of 30 sets of pairwise Standard runs.}}{96}{figure.5.6}}
\newlabel{fig:pairwise-training-testing}{{5.6}{96}{The best training and testing $F_1$-scores obtained from the alignment of 30 sets of pairwise Standard runs}{figure.5.6}{}}
\newlabel{sub:cluster-cluster-results}{{5.5.3}{97}{Probabilistic Matching Results from Cluster-Cluster}{subsection.5.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Probabilistic Matching Results from Cluster-Cluster}{97}{subsection.5.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces  PR curves obtained from running Cluster-Cluster on one of the sets of 4 randomly selected Standard runs (left) and the 3 Beer runs (right). Green dots are performance points obtained from running Cluster-Match at varying m/z and RT tolerance parameters on the same datasets, with their distributions of the points plotted along the marginals. The same first-stage clustering results were used as input to both Cluster-Match and Cluster-Cluster.}}{98}{figure.5.7}}
\newlabel{fig:pr-curve}{{5.7}{98}{PR curves obtained from running Cluster-Cluster on one of the sets of 4 randomly selected Standard runs (left) and the 3 Beer runs (right). Green dots are performance points obtained from running Cluster-Match at varying m/z and RT tolerance parameters on the same datasets, with their distributions of the points plotted along the marginals. The same first-stage clustering results were used as input to both Cluster-Match and Cluster-Cluster}{figure.5.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Running time}{98}{subsection.5.5.4}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Precision, recall and $F_{1}$ values from Cluster-Cluster for randomly selected sets of 2, 3 and 4 Standard runs (averaged) and the Beer runs for various $l$ and thresholding levels $th=\{0.30, 0.60, 0.90\}$. Best results from Cluster-Match and the result of running Cluster-Cluster without the adduct fingerprint term are shown for comparison. Note that for Cluster-Cluster, the results come from using one set of potentially sub-optimal parameters for the second-stage clustering.}}{99}{table.5.3}}
\newlabel{Tab:standard-beer-results}{{5.3}{99}{Precision, recall and $F_{1}$ values from Cluster-Cluster for randomly selected sets of 2, 3 and 4 Standard runs (averaged) and the Beer runs for various $l$ and thresholding levels $th=\{0.30, 0.60, 0.90\}$. Best results from Cluster-Match and the result of running Cluster-Cluster without the adduct fingerprint term are shown for comparison. Note that for Cluster-Cluster, the results come from using one set of potentially sub-optimal parameters for the second-stage clustering}{table.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Conclusions}{99}{section.5.6}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Hierarchical Clustering of LC-MS Peaks}{102}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:hdp}{{6}{102}{Hierarchical Clustering of LC-MS Peaks}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{102}{section.6.1}}
\citation{Tibshirani2004}
\citation{DeSouza2006}
\citation{Tibshirani2004}
\citation{DeSouza2006}
\citation{Tibshirani2004}
\citation{DeSouza2006}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An illustrative example of how the proposed model in HDP-Align simultaneously \textbf  {(1)} performs the clustering of related peaks into within-run local clusters by their RT values, \textbf  {(2)} assigns the peaks to global \ac {RT} clusters shared across runs, and \textbf  {(3)} separates peaks into mass clusters, which correspond to aligned peaksets.}}{103}{figure.6.1}}
\acronymused{RT}
\newlabel{fig-hdp-cartoon}{{6.1}{103}{An illustrative example of how the proposed model in HDP-Align simultaneously \textbf {(1)} performs the clustering of related peaks into within-run local clusters by their RT values, \textbf {(2)} assigns the peaks to global \ac {RT} clusters shared across runs, and \textbf {(3)} separates peaks into mass clusters, which correspond to aligned peaksets}{figure.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Related Work}{103}{section.6.2}}
\citation{teh2005hierarchical}
\citation{teh2012hierarchical}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Hierarchical Dirichlet Process Mixture Model for Alignment}{104}{section.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Graphical model for HDP-Align. $x_{jn}$ is the observed RT value of peak $n$ in file $j$, while $y_{jn}$ is the observed m/z value.}}{104}{figure.6.2}}
\newlabel{fig-platediagram}{{6.2}{104}{Graphical model for HDP-Align. $x_{jn}$ is the observed RT value of peak $n$ in file $j$, while $y_{jn}$ is the observed m/z value}{figure.6.2}{}}
\citation{Perera2011}
\newlabel{eq:draw_ti}{{6.6}{106}{Hierarchical Dirichlet Process Mixture Model for Alignment}{equation.6.3.6}{}}
\newlabel{eq:draw_tik}{{6.7}{106}{Hierarchical Dirichlet Process Mixture Model for Alignment}{equation.6.3.7}{}}
\newlabel{eq:peakdist}{{6.8}{106}{Hierarchical Dirichlet Process Mixture Model for Alignment}{equation.6.3.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Inference}{107}{section.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Updating peak assignments}{107}{subsection.6.4.1}}
\newlabel{eq:table_likelihood}{{6.13}{107}{Updating peak assignments}{subsection.6.4.1}{}}
\newlabel{eq:likelihood-existing-cluster}{{6.14}{107}{Updating peak assignments}{Item.22}{}}
\newlabel{eq:mass_cluster_marg}{{6.15}{108}{Updating peak assignments}{Item.22}{}}
\newlabel{eq:global_cluster_marg}{{6.18}{108}{Updating peak assignments}{Item.23}{}}
\newlabel{eq:existing_global_factors}{{6.19}{108}{Updating peak assignments}{Item.23}{}}
\citation{Lee2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Updating instantiated variables}{109}{subsection.6.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Using the Inference Results}{109}{subsection.6.4.3}}
\newlabel{subsub:feature-matching}{{6.4.3}{109}{Using the Inference Results}{subsection.6.4.3}{}}
\citation{Lee2013}
\citation{Lee2013}
\citation{Lee2013}
\citation{Lee2013}
\citation{Lee2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.4}Isotopic Product and Metabolite Identity Annotations}{110}{subsection.6.4.4}}
\newlabel{subsub:isotopic-product-annotations}{{6.4.4}{110}{Isotopic Product and Metabolite Identity Annotations}{subsection.6.4.4}{}}
\citation{Lange2008}
\citation{Tsai2013a}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Comparisons on the workflow to assign putative annotations on isotopic products and metabolites described in Lee. \textit  {et al.} (2013) \cite  {Lee2013} and in HDP-Align.}}{111}{figure.6.3}}
\newlabel{fig-workflow}{{6.3}{111}{Comparisons on the workflow to assign putative annotations on isotopic products and metabolites described in Lee. \textit {et al.} (2013) \cite {Lee2013} and in HDP-Align}{figure.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Evaluation Study}{111}{section.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}Evaluation Datasets}{111}{subsection.6.5.1}}
\acronymused{RT}
\citation{Voss2011a}
\citation{Pluskal2010}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Total number of runs and features of the selected evaluation datasets. }}{112}{table.6.1}}
\newlabel{tab:hdp-datasets}{{6.1}{112}{Total number of runs and features of the selected evaluation datasets}{table.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.2}Baseline Methods for Evaluation}{112}{subsection.6.5.2}}
\acronymused{RT}
\citation{Lange2008}
\citation{Tsai2013a}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.3}Parameter Optimisations}{113}{subsection.6.5.3}}
\newlabel{sub:parameter-optimisations}{{6.5.3}{113}{Parameter Optimisations}{subsection.6.5.3}{}}
\acronymused{RT}
\acronymused{RT}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Parameters used for HDP-Align}}{113}{table.6.2}}
\newlabel{tab:hdp-parameters-hdpalign}{{6.2}{113}{Parameters used for HDP-Align}{table.6.2}{}}
\citation{Lange2008}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Parameters used for the benchmark methods (SIMA, Join).}}{114}{table.6.3}}
\newlabel{tab:hdp-parameters-benchmark}{{6.3}{114}{Parameters used for the benchmark methods (SIMA, Join)}{table.6.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Results and Discussions}{114}{section.6.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}Proteomic (P1) Results}{114}{subsection.6.6.1}}
\newlabel{sub:proteomic-results}{{6.6.1}{114}{Proteomic (P1) Results}{subsection.6.6.1}{}}
\acronymused{RT}
\acronymused{RT}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Precision-recall values on the different fractions of the Proteomic (P1) dataset.}}{115}{figure.6.4}}
\newlabel{fig:proteomic_results}{{6.4}{115}{Precision-recall values on the different fractions of the Proteomic (P1) dataset}{figure.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Traceplots from three randomly initialised MCMC chains for the number of global clusters across all posterior samples for the largest fraction (000) from the Proteomic (P1) dataset.}}{115}{figure.6.5}}
\newlabel{fig:traceplot_000}{{6.5}{115}{Traceplots from three randomly initialised MCMC chains for the number of global clusters across all posterior samples for the largest fraction (000) from the Proteomic (P1) dataset}{figure.6.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Traceplots from three randomly initialised MCMC chains for the number of global clusters across all posterior samples for the smallest fraction (100) from the Proteomic (P1) dataset.}}{116}{figure.6.6}}
\newlabel{fig:traceplot_100}{{6.6}{116}{Traceplots from three randomly initialised MCMC chains for the number of global clusters across all posterior samples for the smallest fraction (100) from the Proteomic (P1) dataset}{figure.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}Glycomic and Metabolomic Results}{116}{subsection.6.6.2}}
\newlabel{sub:glycomic-metabolomic-results}{{6.6.2}{116}{Glycomic and Metabolomic Results}{subsection.6.6.2}{}}
\citation{Lee2013}
\acronymused{RT}
\acronymused{RT}
\acronymused{RT}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Precision-recall values on the alignment of 10 runs from the Glycomic dataset when $q$ (the strictness of performance evaluation as described in Section\nobreakspace  {}\ref  {sub:Performance-Measures}) is gradually increased.}}{118}{figure.6.7}}
\newlabel{fig:glycomic_results}{{6.7}{118}{Precision-recall values on the alignment of 10 runs from the Glycomic dataset when $q$ (the strictness of performance evaluation as described in Section~\ref {sub:Performance-Measures}) is gradually increased}{figure.6.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Precision-recall values on the alignment of 6 runs from the Metabolomic dataset. The parameter values $(T_{m/z}, T_{rt})$ that produce the best and worst performance in SIMA are also annotated in the Figure (red boxes).}}{118}{figure.6.8}}
\newlabel{fig:metabolomic_results_alignment}{{6.8}{118}{Precision-recall values on the alignment of 6 runs from the Metabolomic dataset. The parameter values $(T_{m/z}, T_{rt})$ that produce the best and worst performance in SIMA are also annotated in the Figure (red boxes)}{figure.6.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Example analysis that can be performed on the clustering objects inferred in a Gibbs sample from HDP-Align. The outer black oval denotes a global RT cluster (generally corresponding to a metabolite compound), while the smaller dotted ovals within denote mass clusters (labelled as mass cluster $A,B,C,D,E,F$). peaks are denoted by the filled circle, with the fill colour indicating the originating run of a peak. Green colours denote additional analysis steps that can be performed on the mass cluster objects.}}{119}{figure.6.9}}
\newlabel{fig:metabolomic_results_annotations}{{6.9}{119}{Example analysis that can be performed on the clustering objects inferred in a Gibbs sample from HDP-Align. The outer black oval denotes a global RT cluster (generally corresponding to a metabolite compound), while the smaller dotted ovals within denote mass clusters (labelled as mass cluster $A,B,C,D,E,F$). peaks are denoted by the filled circle, with the fill colour indicating the originating run of a peak. Green colours denote additional analysis steps that can be performed on the mass cluster objects}{figure.6.9}{}}
\citation{Wang2012}
\citation{Daly2014}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Conclusion}{120}{section.6.7}}
\newlabel{sec:conc}{{6.7}{120}{Conclusion}{section.6.7}{}}
\citation{Smith2013}
\citation{Smith2013a}
\citation{Kuhl2012}
\citation{kotera2012kegg}
\citation{bolton2008pubchem}
\citation{Kind2007}
\citation{Smith2005}
\citation{pence2010chemspider}
\citation{horai2010massbank}
\citation{DaSilva2015}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Substructure Discovery in Tandem Mass Spectometry Data}{122}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:lda}{{7}{122}{Substructure Discovery in Tandem Mass Spectometry Data}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Introduction}{122}{section.7.1}}
\citation{Varmuza1996}
\citation{Hummel2010}
\citation{Heinonen2012a}
\citation{Duhrkop2015}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces The carboxylic acid substructure. In the diagram, R refers to the residue, which is the rest of the metabolite attached to this substructure.}}{123}{figure.7.1}}
\newlabel{fig:cooh}{{7.1}{123}{The carboxylic acid substructure. In the diagram, R refers to the residue, which is the rest of the metabolite attached to this substructure}{figure.7.1}{}}
\citation{yang2013molecular}
\citation{nguyen2013ms}
\citation{van2016urinary}
\citation{ma2014ms2analyzer}
\citation{Sweeney2014}
\citation{Scott1994}
\citation{Hummel2010}
\citation{Duhrkop2015}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Related Work}{124}{section.7.2}}
\citation{chen2010probabilistic}
\citation{zhang2015exploiting}
\citation{rogers2005latent}
\citation{chen2010probabilistic}
\citation{zhang2015exploiting}
\citation{rogers2005latent}
\citation{Bocker2009}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Statement of Original Work}{125}{section.7.3}}
\citation{Smith2006}
\citation{Stravs2013}
\newlabel{sub:ms2lda-workflow}{{7.4}{126}{A Workflow for Substructure Discoveries and Annotations}{section.7.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}A Workflow for Substructure Discoveries and Annotations}{126}{section.7.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces \textbf  {A.} LDA applied to text decomposes a document into its topic distributions (e.g. football, business and enrivonment topics). \textbf  {B.} Similarly, MS2LDA decomposes a fragmentation spectrum into its topics (Mass2Motifs) that can be characterised as asparagine, hexose and adenine related. Each fragmentation spectra comprise of one or more Mass2Motifs. \textbf  {C.} Schematic overview of the MS2LDA workflow.}}{127}{figure.7.2}}
\newlabel{fig:text2frags}{{7.2}{127}{\textbf {A.} LDA applied to text decomposes a document into its topic distributions (e.g. football, business and enrivonment topics). \textbf {B.} Similarly, MS2LDA decomposes a fragmentation spectrum into its topics (Mass2Motifs) that can be characterised as asparagine, hexose and adenine related. Each fragmentation spectra comprise of one or more Mass2Motifs. \textbf {C.} Schematic overview of the MS2LDA workflow}{figure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces The matrix of co-occurrences of fragment and loss features (rows) in each fragmentation spectrum linked to a parent MS1 peak (columns). Entries of the matrix are the counts of the feature from the normalized (0 – 100 scale) intensities.}}{128}{figure.7.3}}
\newlabel{fig:m2lda-matrix}{{7.3}{128}{The matrix of co-occurrences of fragment and loss features (rows) in each fragmentation spectrum linked to a parent MS1 peak (columns). Entries of the matrix are the counts of the feature from the normalized (0 – 100 scale) intensities}{figure.7.3}{}}
\citation{Sievert2014}
\@writefile{toc}{\contentsline {subsubsection}{MS2LDAVis}{129}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Screenshot of MS2LDAVis. See text for explanations of the different panels.}}{130}{figure.7.4}}
\newlabel{fig:m2ldavis-main}{{7.4}{130}{Screenshot of MS2LDAVis. See text for explanations of the different panels}{figure.7.4}{}}
\citation{Bocker2009}
\citation{Bocker2007}
\citation{Kind2007}
\citation{Creek2011}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Evaluation Study}{132}{section.7.5}}
\newlabel{sub:ms2lda-datasets}{{7.5.1}{132}{Evaluation Dataset}{subsection.7.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Evaluation Dataset}{132}{subsection.7.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Beer samples used for evaluation dataset.}}{132}{table.7.1}}
\newlabel{tab:beer-sample-details}{{7.1}{132}{Beer samples used for evaluation dataset}{table.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Model Comparison}{132}{subsection.7.5.2}}
\citation{wallach2009evaluation}
\citation{Griffiths2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}Biochemical Analysis}{133}{subsection.7.5.3}}
\citation{yang2013molecular}
\citation{nguyen2013ms}
\citation{van2016urinary}
\@writefile{toc}{\contentsline {subsubsection}{Validation to Reference Standard Molecules}{134}{section*.17}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison to Spectral Clustering}{134}{section*.18}}
\@writefile{toc}{\contentsline {subsubsection}{Differential Analysis of Mass2Motifs}{134}{section*.19}}
\citation{Smith2006}
\citation{Scheltema2011}
\citation{tomfohr2005pathway}
\citation{tarca2013comparison}
\citation{tarca2013comparison}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Results \& Discussions}{135}{section.7.6}}
\newlabel{sub:lda-model-comparison}{{7.6.1}{135}{Model Comparison}{subsection.7.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Model Comparison}{135}{subsection.7.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Results of model comparisons of LDA and multinomial mixture model on the Beer3 data. The lower perplexity values for $K>100$ demonstrates that LDA provides a better model fit on the held-out data when compared to the mixture model.}}{136}{figure.7.5}}
\newlabel{fig:m2lda-perplexity}{{7.5}{136}{Results of model comparisons of LDA and multinomial mixture model on the Beer3 data. The lower perplexity values for $K>100$ demonstrates that LDA provides a better model fit on the held-out data when compared to the mixture model}{figure.7.5}{}}
\newlabel{sub:lda-biological-findings}{{7.6.2}{136}{Biochemical Analysis}{subsection.7.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}Biochemical Analysis }{136}{subsection.7.6.2}}
\citation{ma2014ms2analyzer}
\citation{horai2010massbank}
\@writefile{lot}{\contentsline {table}{\numberline {7.2}{\ignorespaces Mass2Motif coverage of MS1 peaks by percentage of MS1 peaks that can be explained by at least one structurally annotated Mass2Motif for the files acquired in positive ionization mode.}}{137}{table.7.2}}
\newlabel{tab:ms2lda-coverage}{{7.2}{137}{Mass2Motif coverage of MS1 peaks by percentage of MS1 peaks that can be explained by at least one structurally annotated Mass2Motif for the files acquired in positive ionization mode}{table.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Three spectra, from the beer3 positive ionization mode file, each of which includes Mass2Motif 19, annotated as the plant derived ferulic acid substructure. A-C highlight mass fragments and neutral losses (arrows originating at the precursor ions) included in Mass2Motif 19 (fragments not explained by Mass2Motif 19 are light grey). Ferulic acid substructure is illustrated at the top of D, while the boxplot in D shows how common each fragment or loss features (representative of the substructure) are found in the 11 spectra explained by Mass2Motif 19 found in the dataset. Features highlighted in bold are consistently present in Mass2Motifs inferred across the four beer samples.}}{138}{figure.7.6}}
\newlabel{fig:m2lda-ferulic-acid}{{7.6}{138}{Three spectra, from the beer3 positive ionization mode file, each of which includes Mass2Motif 19, annotated as the plant derived ferulic acid substructure. A-C highlight mass fragments and neutral losses (arrows originating at the precursor ions) included in Mass2Motif 19 (fragments not explained by Mass2Motif 19 are light grey). Ferulic acid substructure is illustrated at the top of D, while the boxplot in D shows how common each fragment or loss features (representative of the substructure) are found in the 11 spectra explained by Mass2Motif 19 found in the dataset. Features highlighted in bold are consistently present in Mass2Motifs inferred across the four beer samples}{figure.7.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Validation to Reference Standard Molecules}{138}{section*.20}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison to Spectral Clustering}{139}{section*.21}}
\@writefile{lot}{\contentsline {table}{\numberline {7.3}{\ignorespaces Annotations of the Mass2Motifs associated to the fragmentation spectra of the peaks generated by the standard molecules shown in Figure\nobreakspace  {}\ref  {fig:m2lda-standards}. The degree of a Mass2Motif indicates the number of MS2 fragmentation spectra in Beer3 positive ionization mode data having the fragment or loss features that can be explained by the Mass2Motif. }}{140}{table.7.3}}
\newlabel{tab:ms2lda-standards}{{7.3}{140}{Annotations of the Mass2Motifs associated to the fragmentation spectra of the peaks generated by the standard molecules shown in Figure~\ref {fig:m2lda-standards}. The degree of a Mass2Motif indicates the number of MS2 fragmentation spectra in Beer3 positive ionization mode data having the fragment or loss features that can be explained by the Mass2Motif}{table.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Mass2Motif spectra of identified standard molecules A) L-histidine, B) L-phenylalanine, C) L-tryptophan, and D) adenosine, with their characterized motifs (see Table\nobreakspace  {}\ref  {tab:ms2lda-standards}) indicated by colours.}}{141}{figure.7.7}}
\newlabel{fig:m2lda-standards}{{7.7}{141}{Mass2Motif spectra of identified standard molecules A) L-histidine, B) L-phenylalanine, C) L-tryptophan, and D) adenosine, with their characterized motifs (see Table~\ref {tab:ms2lda-standards}) indicated by colours}{figure.7.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces Mass2Motifs 19 and 58 were found to be representative of ferulic acid and ethylphenol, respectively. 11 fragmentation spectra can be explained by M2M_19, while 42 spectra can be explained by M2M_58. However, one spectra (shown as a gray node in the Figure) can be explained by both Mass2Motifs, but this is not possible in spectral clustering.}}{142}{figure.7.8}}
\newlabel{fig:m2lda-combined-m2m}{{7.8}{142}{Mass2Motifs 19 and 58 were found to be representative of ferulic acid and ethylphenol, respectively. 11 fragmentation spectra can be explained by M2M_19, while 42 spectra can be explained by M2M_58. However, one spectra (shown as a gray node in the Figure) can be explained by both Mass2Motifs, but this is not possible in spectral clustering}{figure.7.8}{}}
\citation{tomfohr2005pathway}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces Cosine clustering results of spectra drawn from the ferulic acid based cluster and the ethylphenol based cluster (similar to M2M_19 and M2M_58). The last row represents a fragmentation spectrum that contains both substructures, but in the clustering approach, the spectra will be placed into one of the clusters based on its cosine similarity. In LDA, this spectrum can be explained by Mass2Motifs that characterise both substructures.}}{143}{figure.7.9}}
\newlabel{fig:m2lda-cosine-clustering}{{7.9}{143}{Cosine clustering results of spectra drawn from the ferulic acid based cluster and the ethylphenol based cluster (similar to M2M_19 and M2M_58). The last row represents a fragmentation spectrum that contains both substructures, but in the clustering approach, the spectra will be placed into one of the clusters based on its cosine similarity. In LDA, this spectrum can be explained by Mass2Motifs that characterise both substructures}{figure.7.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Differential Analysis of Mass2Motifs}{143}{section*.22}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces Log fold change heat-maps for the A) guanine and B) pentose loss Mass2Motifs. Each row is an annotated parent MS1 peak and columns represent different beer extracts. Bold names for parent MS1 peaks could confidently be matched to reference compounds, while italic names are for those that are annotated at a lower degree of confidence. }}{144}{figure.7.10}}
\newlabel{fig:m2lda-heatmaps}{{7.10}{144}{Log fold change heat-maps for the A) guanine and B) pentose loss Mass2Motifs. Each row is an annotated parent MS1 peak and columns represent different beer extracts. Bold names for parent MS1 peaks could confidently be matched to reference compounds, while italic names are for those that are annotated at a lower degree of confidence}{figure.7.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Substructure Discoveries Across Many Fragmentation Files}{145}{section.7.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}Multi-file LDA Model}{145}{subsection.7.7.1}}
\newlabel{eq:dir-multi-1a}{{7.5}{145}{Multi-file LDA Model}{equation.7.7.5}{}}
\newlabel{eq:dir-multi-1b}{{7.6}{145}{Multi-file LDA Model}{equation.7.7.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.11}{\ignorespaces Graphical model of the multi-file LDA model. The addition to the standard LDA model is the plate on $F$ that denotes an index over the files, $f=1,...,F$. Circles denotes random variables, while the shaded node denotes the observed word value.}}{146}{figure.7.11}}
\newlabel{fig:lda-multifile-lda-diagram}{{7.11}{146}{Graphical model of the multi-file LDA model. The addition to the standard LDA model is the plate on $F$ that denotes an index over the files, $f=1,...,F$. Circles denotes random variables, while the shaded node denotes the observed word value}{figure.7.11}{}}
\newlabel{eq:dir-multi-2a}{{7.7}{146}{Multi-file LDA Model}{equation.7.7.7}{}}
\newlabel{eq:dir-multi-2b}{{7.8}{146}{Multi-file LDA Model}{equation.7.7.8}{}}
\newlabel{eq:multifile-lda-gibbs}{{7.9}{146}{Multi-file LDA Model}{equation.7.7.9}{}}
\newlabel{eq:multifile-lda-gibbs-likelihood}{{7.10}{146}{Multi-file LDA Model}{equation.7.7.10}{}}
\citation{Minka2003}
\newlabel{eq:multifile-lda-gibbs-prior}{{7.11}{147}{Multi-file LDA Model}{equation.7.7.11}{}}
\newlabel{eq:multifile-lda-gibbs-combined}{{7.12}{147}{Multi-file LDA Model}{equation.7.7.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}Results \& Discussion}{148}{subsection.7.7.2}}
\@writefile{lot}{\contentsline {table}{\numberline {7.4}{\ignorespaces Five global Mass2Motifs inferred from multi-file LDA. For each Mass2Motif, the top features above threshold are listed. Features characterised as key to the substructure from the previous individual LDA analyses are shown in bold.}}{148}{table.7.4}}
\newlabel{tab:multifile-results}{{7.4}{148}{Five global Mass2Motifs inferred from multi-file LDA. For each Mass2Motif, the top features above threshold are listed. Features characterised as key to the substructure from the previous individual LDA analyses are shown in bold}{table.7.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.12}{\ignorespaces Fragmentation spectra from different Beer extracts found by multi-file LDA to contain the same Mass2Motif (M2M_17) characterised as the ferulic acid substructure.}}{149}{figure.7.12}}
\newlabel{fig:multifile-lda}{{7.12}{149}{Fragmentation spectra from different Beer extracts found by multi-file LDA to contain the same Mass2Motif (M2M_17) characterised as the ferulic acid substructure}{figure.7.12}{}}
\citation{Teh2006}
\@writefile{lof}{\contentsline {figure}{\numberline {7.13}{\ignorespaces Posterior alpha values for the \textbf  {A)} ferulic acid, \textbf  {B)} histidine and \textbf  {C)} leucine Mass2Motifs across the different beer files. }}{150}{figure.7.13}}
\newlabel{fig:multifile-lda-alpha}{{7.13}{150}{Posterior alpha values for the \textbf {A)} ferulic acid, \textbf {B)} histidine and \textbf {C)} leucine Mass2Motifs across the different beer files}{figure.7.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Conclusion}{150}{section.7.8}}
\citation{griffiths2004hierarchical}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{152}{chapter.8}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{c:conclusion}{{8}{152}{Conclusion}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Summary of Contributions}{152}{section.8.1}}
\citation{Rogers2012}
\citation{Rogers2012}
\citation{Rogers2012}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Future Work}{153}{section.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Improved Generative Models to Cluster Related Peaks}{154}{subsection.8.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Using the Generative Models for Identification}{154}{subsection.8.2.2}}
\citation{bolton2008pubchem}
\citation{Blei2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Data Visualisation and Interpretation}{155}{subsection.8.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Topic Modelling of Fragmentation Data}{155}{subsection.8.2.4}}
\citation{teh2012hierarchical}
\citation{griffiths2004hierarchical}
\citation{kang2012transfer}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Summary and Conclusions}{156}{section.8.3}}
\bibstyle{IEEEtran}
\bibdata{bibliography/dissertation}
\bibcite{Tsai2013a}{1}
\bibcite{Lee2013}{2}
\bibcite{mann2003proteomic}{3}
\bibcite{Panopoulos2012}{4}
\bibcite{Hirai2004}{5}
\bibcite{Fiehn2002}{6}
\bibcite{metzker2010sequencing}{7}
\bibcite{Alonso2015}{8}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{158}{section.8.3}}
\bibcite{Pan2007}{9}
\bibcite{Smith2014}{10}
\bibcite{Cao2015}{11}
\bibcite{Pedrioli2004}{12}
\bibcite{martens2011mzml}{13}
\bibcite{Tautenhahn2008}{14}
\bibcite{Pluskal2010}{15}
\bibcite{Katajamaa2007}{16}
\bibcite{Castillo2011}{17}
\bibcite{chokkathukalam2014stable}{18}
\bibcite{podwojski2009retention}{19}
\bibcite{Sakoe1978}{20}
\bibcite{Nielsen1998}{21}
\bibcite{Christin2008}{22}
\bibcite{Windig2007}{23}
\bibcite{VanNederkassel2006}{24}
\bibcite{Listgarten2005}{25}
\bibcite{Smith2006}{26}
\bibcite{Lange2007}{27}
\bibcite{Fischler1981}{28}
\bibcite{Lange2008}{29}
\bibcite{Hoffmann2012a}{30}
\bibcite{Ballardini2011}{31}
\bibcite{Voss2011a}{32}
\bibcite{Duran2003}{33}
\bibcite{Wang2013}{34}
\bibcite{Lin2013}{35}
\bibcite{Snider2007}{36}
\bibcite{Keller2008}{37}
\bibcite{Scheltema2009a}{38}
\bibcite{Scheltema2011}{39}
\bibcite{Rogers2012}{40}
\bibcite{Kuhl2012}{41}
\bibcite{Sumner2007}{42}
\bibcite{Kind2006}{43}
\bibcite{Dunn2012}{44}
\bibcite{DaSilva2015}{45}
\bibcite{Creek2011}{46}
\bibcite{Stanstrup2015}{47}
\bibcite{Rogers2009a}{48}
\bibcite{Daly2014}{49}
\bibcite{Hufsky2014}{50}
\bibcite{kotera2012kegg}{51}
\bibcite{horai2010massbank}{52}
\bibcite{pence2010chemspider}{53}
\bibcite{Xia2010}{54}
\bibcite{Krumsiek2011a}{55}
\bibcite{Krumsiek2012}{56}
\bibcite{Gieger2008}{57}
\bibcite{DeVos2007a}{58}
\bibcite{mamas2011role}{59}
\bibcite{Gibney2005}{60}
\bibcite{Kell2006}{61}
\bibcite{Kanehisa2010}{62}
\bibcite{caspi2008metacyc}{63}
\bibcite{cottret2010metexplore}{64}
\bibcite{Sandin2014}{65}
\bibcite{Chawade2015}{66}
\bibcite{Podwojski2009}{67}
\bibcite{Hoffmann2007}{68}
\bibcite{gross2006mass}{69}
\bibcite{Gika2014}{70}
\bibcite{Megger2013}{71}
\bibcite{xu2005survey}{72}
\bibcite{Jain2010}{73}
\bibcite{DeSouza2006}{74}
\bibcite{Frank2007}{75}
\bibcite{Silva2014}{76}
\bibcite{Allen2014}{77}
\bibcite{Allen2016}{78}
\bibcite{Heinonen2012a}{79}
\bibcite{Duhrkop2015}{80}
\bibcite{Rasmussen2000}{81}
\bibcite{gelman2014bayesian}{82}
\bibcite{murphy2012machine}{83}
\bibcite{hjort2010bayesian}{84}
\bibcite{ferguson1973bayesian}{85}
\bibcite{teh2011dirichlet}{86}
\bibcite{ishwaran2011gibbs}{87}
\bibcite{frigyik2010introduction}{88}
\bibcite{aldous1985exchangeability}{89}
\bibcite{teh2005hierarchical}{90}
\bibcite{teh2012hierarchical}{91}
\bibcite{kim2006hierarchical}{92}
\bibcite{Blei2003}{93}
\bibcite{rogers2005latent}{94}
\bibcite{weinshall2013lda}{95}
\bibcite{das2015gaussian}{96}
\bibcite{carpenter2010integrating}{97}
\bibcite{Smith2013}{98}
\bibcite{wandy2015incorporating}{99}
\bibcite{Gusfield1989}{100}
\bibcite{Kuhn1955}{101}
\bibcite{Maximum2011}{102}
\bibcite{Smith2013a}{103}
\bibcite{Smith2015}{104}
\bibcite{Melamud2010}{105}
\bibcite{Brodsky2010}{106}
\bibcite{Landan2009}{107}
\bibcite{Thompson1994}{108}
\bibcite{Notredame2000}{109}
\bibcite{Penn2010}{110}
\bibcite{Redelings2005}{111}
\bibcite{Bradley2009}{112}
\bibcite{Jeong2012}{113}
\bibcite{GhanatBari2014b}{114}
\bibcite{Sandin2013}{115}
\bibcite{Tibshirani2004}{116}
\bibcite{Perera2011}{117}
\bibcite{Wang2012}{118}
\bibcite{bolton2008pubchem}{119}
\bibcite{Kind2007}{120}
\bibcite{Smith2005}{121}
\bibcite{Varmuza1996}{122}
\bibcite{Hummel2010}{123}
\bibcite{yang2013molecular}{124}
\bibcite{nguyen2013ms}{125}
\bibcite{van2016urinary}{126}
\bibcite{ma2014ms2analyzer}{127}
\bibcite{Sweeney2014}{128}
\bibcite{Scott1994}{129}
\bibcite{chen2010probabilistic}{130}
\bibcite{zhang2015exploiting}{131}
\bibcite{Bocker2009}{132}
\bibcite{Stravs2013}{133}
\bibcite{Sievert2014}{134}
\bibcite{Bocker2007}{135}
\bibcite{wallach2009evaluation}{136}
\bibcite{Griffiths2004}{137}
\bibcite{tomfohr2005pathway}{138}
\bibcite{tarca2013comparison}{139}
\bibcite{Minka2003}{140}
\bibcite{griffiths2004hierarchical}{141}
\bibcite{kang2012transfer}{142}
