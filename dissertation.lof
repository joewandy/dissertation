\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The building blocks of the genome are the DNA nucleotides. In the transcriptome, the building blocks are the nitrogenous bases that comprise the RNA. In proteomics, the 20 amino acids residues make up the polypeptide comprising a protein molecule. In contrast, the building blocks of metabolites are the atoms (usually CHNOPS: carbon, hydrogen, nitrogen, oxygen, phospor and sulphur) that comprise a large range of compounds, such as lipids, amino acids, vitamins, etc., with varying physical and chemical properties}}{5}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces A typical LC-MS set-up. High performance liquid chromatography instruments are used to separate metabolites (by their chemical properties) in the sample before they are gradually introduced into the mass spectrometer.}}{9}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces The resulting raw data (ion chromatograms) produced from an LC-MS experiment. We can view the data as a 3D profile (left) and as a 2D profile seen from the top (right). A slice of the data on the m/z axis is the mass spectrum. Each mass spectrum is produced by a scan of the mass spectrometer. A collection of mass spectra is produced over the whole range of retention time. A point in the raw data is thus characterised by its intensity value on the m/z and retention time axes.}}{9}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Preprocessing pipeline of LC-MS metabolomics data.}}{11}{figure.2.4}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustrative example of the incorporation of grouping information into the similarity score. Each node in the figure is a peak feature, and dotted ovals represent groups of related peaks, e.g. isotopes, fragments, etc. Initially weights (e.g. $W_{AE}$) are computed for pairs of peaks (one from each run) with m/z and RT within pre-defined thresholds. These weights are converted into an overall score by incorporating grouping information. For example, peak pairs $(A,E)$ and $(B,G)$ are both within the threshold. Because $A$ and $B$ are in the same group, and $E$ and $G$ are in the same group, the weights between pairs $(A,E)$ and $(B,G)$ are upweighted. Peak $J$ is not related to any peaks that could be matched with $A$'s related peaks and the similarity between $A$ and $J$ is therefore downweighted (because $\alpha \leq 1$). The same applies to similarities between pairs $(C,H)$ and $(D,I)$.}}{26}{figure.4.1}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P1 dataset.}}{39}{figure.4.2}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {P1 Fraction 000}}}{39}{subfigure.2.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {P1 Fraction 100}}}{39}{subfigure.2.2}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Precision and recall training performance for all parameters (m/z, RT tolerance, $\alpha $ and $g_{tol}$) varied in the experiment for the fractions containing the most (a) and the least (b) number of features in the P2 dataset.}}{40}{figure.4.3}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {P2 Fraction 000}}}{40}{subfigure.3.1}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {P2 Fraction 100}}}{40}{subfigure.3.2}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Training performance shows the best F$_1$ scores obtained by each method on 30 pairs of randomly-selected metabolomic and glycomic training sets.}}{43}{figure.4.4}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Testing performance shows how well each method generalise on the 30 different testing sets, each evaluated using the optimal training parameters from its corresponding training set.}}{43}{figure.4.5}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Comparisons in matching performance when greedy clustering with retention time (MWG(RT)) and peak shape correlations (MWG(RT+PS)) are used.}}{44}{figure.4.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces An illustration of the proposed methods. The results from inference on the PrecursorCluster model are the set of peaks and their assignments to IP clusters through any of the predefined list of transformation (Fig.\nobreakspace {}\ref {fig:01}A). As a starting point, each observed peak feature generates a candidate IP cluster, having the cluster's mass computed through the M+H transformation of the observed peak's m/z value. In Fig.\nobreakspace {}\ref {fig:01}A, this results Peak 1 generating the candidate cluster with mass $q_a$ Peak 4 generating the candidate cluster with mass $q_b$ (other candidate IP clusters produced by Peak 2, 3 and 5 are not shown in the figure). As a result from inference, Peak 1 and Peak 2 are clustered to $q_a$ through the transformation types M+H and M+Na respectively with probability 1.0. Peak 3 has a valid transformation path to $q_a$, but it is not allowed to join that cluster since its intensity is greater than the intensity of the precursor peak. Peak 4 can either form a cluster with $q_a$ through the 2M+H transformation (with probability 0.62) or, through the M+H transformation on itself, form its own candidate IP cluster having the precursor mass $q_b$ (with probability 0.38.) The latter allows for Peak 5 to join that cluster too through the M+NH4 transformation with probability 0.43. For alignment, the final clustering result is established by taking the assignment that has the highest probability for each peak feature. Alignment of IP clusters can be performed by matching IP clusters according to their posterior precursor mass and RT values across runs (Fig.\nobreakspace {}\ref {fig:01}B) or by further clustering them into top-level clusters in a second-stage clustering process (Fig.\nobreakspace {}\ref {fig:01}C). The matching of peak features of IP clusters into the same top-level cluster is constructed by matching peak features that have the same transformation types together. These are shown as the gray dotted lines in Figures\nobreakspace {}\ref {fig:01}B \& C.}}{51}{figure.5.1}
\contentsline {figure}{\numberline {5.2}{\ignorespaces Ionization product cluster sizes for all runs in the Standard and Beer datasets. For any given size, the number of clusters are generally more consistent in the Beer runs compared to the Standard runs, which shows greater variability due to the differences in the number of peak features per run.}}{64}{figure.5.2}
\contentsline {figure}{\numberline {5.3}{\ignorespaces \textbf {(A)} Barcharts showing the counts of transformation types in each Standard run. We see that the top two most-occurring transformation types are M+Na and M+ACN+H. \textbf {(B)} Boxplots with confidence interval showing the probabilities of transformation types across all Standard runs. With the exception of M+2ACN+H, we observe high confidence in the assignment of peaks into an IP cluster through any of the listed transformation types.}}{65}{figure.5.3}
\contentsline {figure}{\numberline {5.4}{\ignorespaces \textbf {(A)} Barcharts showing the counts of transformation types in each Beer run. We see that the top three most-occurring transformation types are M+Na, M+NH4 and M+CH3OH+H. \textbf {(B)} Boxplots with confidence interval showing the probabilities of transformation types across all Beer runs. With the exception of M+ACN+H and M+ACN+Na, we observe high confidence in the assignment of peaks into an IP cluster through any of the listed transformation types.}}{65}{figure.5.4}
\contentsline {figure}{\numberline {5.5}{\ignorespaces Boxplots with confidence interval showing the probabilities of transformation types across all Standard runs when both the adduct transformation types (Table\nobreakspace {}\ref {Tab:transformation}) and the C$_{13}$-isotope transformation type are used. The increase in assignment uncertainties compared to Figure\nobreakspace {}\ref {fig:trans-beer}B makes it difficult to establish consistent MAP-assignment of peak features into the same IP clusters across runs. }}{66}{figure.5.5}
\contentsline {figure}{\numberline {5.6}{\ignorespaces All the training results obtained by varying the m/z and RT window parameters from the alignment of the entire 30 sets of pairwise Standard runs (top row) and the 3 Beer runs (bottom row). For MWG, the grouping parameter $t$ and score contribution $\alpha $ were also varied, while for Cluster-Match, the same set parameters of first-stage clustering was used for all input files.}}{67}{figure.5.6}
\contentsline {figure}{\numberline {5.7}{\ignorespaces The best training and testing $F_1$-scores obtained from the alignment of 30 sets of Standard runs.}}{68}{figure.5.7}
\contentsline {figure}{\numberline {5.8}{\ignorespaces PR curves obtained from running Cluster-Cluster on one of the sets of 4 randomly selected Standard runs (left) and the 3 Beer runs (right). Green dots are performance points obtained from running Cluster-Match at varying m/z and RT tolerance parameters on the same datasets, with their distributions of the points plotted along the marginals. The same first-stage clustering results were used as input to both Cluster-Match and Cluster-Cluster.}}{69}{figure.5.8}
\contentsline {figure}{\numberline {5.9}{\ignorespaces Different IP clusters (2, 15, 24, 9), found in a set of four different Standard runs, which have been putatively identified as corresponding to Melatonin and whose member peaks should therefore be aligned according to the ground truth. Within each run, the first-stage ionization product clustering (PrecursorCluster) gives us the initial assignment of peaks to an IP cluster according to their m/z, RT values and possible transformation types. Here, member peaks are assigned to an IP cluster according to their maximum \textit {a posteriori} probabilities. In the Figure, the posterior transformation type of a peak and its corresponding probability are annotated as a labelled arrow and the bracketed number beside. Across runs, the second-stage clustering (Cluster-Cluster) brings similar IP clusters together, producing an alignment result. The probability of the four peaks $[M+H]^+$ peaks in the Figure to be matched together into a single aligned peakset is 0.87 when the adduct fingerprint term is used and 0.45 without. }}{71}{figure.5.9}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces An illustrative example of how the proposed model in HDP-Align simultaneously \textbf {(1)} performs the clustering of related peak features into within-run local clusters by their RT values, \textbf {(2)} assigns the peak features to global \ac {RT} clusters shared across runs, and \textbf {(3)} separates peak features into mass clusters, which correspond to aligned peaksets.}}{75}{figure.6.1}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Comparisons on the workflow to assign putative annotations on isotopic products and metabolites described in \cite {Lee2013} and in HDP-Align.}}{83}{figure.6.2}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Precision-recall values on the different fractions of the Proteomic (P1) dataset.}}{88}{figure.6.3}
\contentsline {figure}{\numberline {6.4}{\ignorespaces Precision-recall values on the alignment of 10 runs from the Glycomic dataset when $q$ (the strictness of performance evaluation as described in Section\nobreakspace {}\ref {sub:Performance-Measures}) is gradually increased.}}{89}{figure.6.4}
\contentsline {figure}{\numberline {6.5}{\ignorespaces Precision-recall values on the alignment of 6 runs from the Metabolomic dataset. The parameter values $(T_{m/z}, T_{rt})$ that produce the best and worst performance in SIMA are also annotated in the Figure (red boxes).}}{90}{figure.6.5}
\contentsline {figure}{\numberline {6.6}{\ignorespaces Example analysis that can be performed on the clustering objects inferred in a Gibbs sample from HDP-Align. The outer black oval denotes a global RT cluster (generally corresponding to a metabolite compound), while the smaller dotted ovals within denote mass clusters (labelled as mass cluster $A,B,C,D,E,F$). Peak features are denoted by the filled circle, with the fill colour indicating the originating run of a peak. Green colours denote additional analysis steps that can be performed on the mass cluster objects. \textbf {REDRAW TO LOOK NICER?}}}{91}{figure.6.6}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Figure 1: Analogy between LDA for text-mining and MS2LDA. In this example, we can see that traditional LDA has extracted topics that can be interpreted as ‘football related’, ‘business-related’ and ‘environment related’. Each document is a combination of different topics. In a similar manner, MS2LDA extracts different sets of concurring mass fragments or losses (Mass2Motifs) from the fragmentation spectra of precursor ions that can be interpreted as ‘Asparagine-related’, ‘Hexose-related’ and ‘Adenine-related’. Each fragmentation spectra is made up of one or more Mass2Motifs.}}{95}{figure.7.1}
\contentsline {figure}{\numberline {7.2}{\ignorespaces Schematic overview of the MS2LDA workflow..}}{96}{figure.7.2}
\contentsline {figure}{\numberline {7.3}{\ignorespaces The data-frame extracted from fragmentation data: a matrix of XCMS-picked MS1 peaks (columns) and binned mass fragment (and neutral loss) features with normalized (0 – 100 scale) intensities.}}{98}{figure.7.3}
\addvspace {10\p@ }
\addvspace {10\p@ }
